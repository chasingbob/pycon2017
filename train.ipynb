{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs. Cats with Tensorflow and Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](data/woof_meow.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have chosen the Dogs vs. Cats data set from the popular Kaggle competition for the small demo.\n",
    "\n",
    "For traditional ML this is a difficult problem, there is so much overlap between cats and dogs being colour, texture and shape. For Deep Learning this is a fairly simple problem, the cutting edge models obtains a 97% accuracy, and my toy model for the purpose of showing you some code obtains a 90% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "\n",
    "import os\n",
    "from skimage import color, io\n",
    "from scipy.misc import imresize, imsave\n",
    "from glob import glob\n",
    "import random as rnd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_img(file_name):\n",
    "    plt.savefig(file_name, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_batch(X, iteration, batch_size):\n",
    "    i = iteration * batch_size\n",
    "    j = iteration * batch_size + batch_size\n",
    "    return X[i:j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = './data/train'\n",
    "image_size = 128\n",
    "\n",
    "cat_files_path = os.path.join(data_path + '/cats', 'cat.*.jpg')\n",
    "dog_files_path = os.path.join(data_path + '/dogs', 'dog.*.jpg')\n",
    "\n",
    "cat_files = sorted(glob(cat_files_path))\n",
    "dog_files = sorted(glob(dog_files_path))\n",
    "\n",
    "file_count = len(cat_files) + len(dog_files)\n",
    "\n",
    "images = np.zeros((file_count, image_size, image_size, 3), dtype='float64')\n",
    "labels = np.zeros(file_count)\n",
    "count = 0\n",
    "for f in cat_files[:1000]:\n",
    "    try:\n",
    "        img = io.imread(f)\n",
    "        new_img = imresize(img, (image_size, image_size, 3))\n",
    "        new_img = np.array(new_img) / 255.\n",
    "        images[count] = new_img\n",
    "        labels[count] = 0\n",
    "        count += 1\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "for f in dog_files[:1000]:\n",
    "    try:\n",
    "        img = io.imread(f)\n",
    "        new_img = imresize(img, (image_size, image_size, 3))\n",
    "        new_img = np.array(new_img) / 255.\n",
    "        images[count] = np.array(new_img)\n",
    "        labels[count] = 1\n",
    "        count += 1\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_figheight(12)\n",
    "fig.set_figwidth(12)\n",
    "\n",
    "for num,img_data in enumerate(images[1000:1025]):\n",
    "    sub = fig.add_subplot(5,5,num+1)\n",
    "    sub.imshow(img_data)\n",
    "    #plt.title('cat', fontsize=18)\n",
    "    sub.axes.get_xaxis().set_visible(False)\n",
    "    sub.axes.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = images[1001]\n",
    "img = io.imread('data/building.jpg')\n",
    "img = img[150:280, 150:280]\n",
    "new_img = imresize(img, (image_size, image_size, 3))\n",
    "new_img = np.array(new_img) / 255.\n",
    "\n",
    "plt.imshow(new_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height, width, channels = new_img.shape\n",
    "img_gray = new_img.mean(axis=2).astype(np.float32)\n",
    "img_gray2 = img_gray.reshape(1, height, width, 1)\n",
    "\n",
    "plt.imshow(img_gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmap = np.zeros(shape=(7, 7, 1, 2), dtype=np.float32)\n",
    "fmap[:, 3, 0, 0] = 1\n",
    "fmap[3, :, 0, 1] = 1\n",
    "fmap[:, :, 0, 0]\n",
    "plt.imshow(fmap[:, :, 0, 0])\n",
    "plt.show()\n",
    "plt.imshow(fmap[:, :, 0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, height, width, 1))\n",
    "feature_maps = tf.constant(fmap)\n",
    "convolution = tf.nn.conv2d(X, feature_maps, strides=[1,1,1,1], padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    output = convolution.eval(feed_dict={X: img_gray2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(output[0, :, :, 0])\n",
    "plt.show()\n",
    "#imsave('data/vertical.png', output[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(output[0, :, :, 1])\n",
    "plt.show()\n",
    "#imsave('data/horizontal.png', output[0, :, :, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](data/vertical.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](data/horizontal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(images, labels, test_size=0.15, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, Y_val, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_maxpool(inputs, num_filters=32, name='conv-maxpool'):\n",
    "    with tf.name_scope(name):\n",
    "        conv = tf.layers.conv2d(\n",
    "            inputs=inputs,\n",
    "            filters=num_filters,\n",
    "            kernel_size=[3, 3],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "\n",
    "        pool = tf.nn.max_pool(conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "        return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('placeholders'):\n",
    "        with tf.name_scope('X'):\n",
    "            X = tf.placeholder(tf.float32, shape=[None, image_size, image_size, 3], name=\"X\")\n",
    "        with tf.name_scope('y'):\n",
    "            y = tf.placeholder(tf.int32, shape=[None], name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('model'):\n",
    "        convmax1 = conv_maxpool(inputs=X, num_filters=32, name='conv-max-1')\n",
    "        convmax2 = conv_maxpool(inputs=convmax1, num_filters=64, name='conv-max-2')\n",
    "        convmax3 = conv_maxpool(inputs=convmax2, num_filters=128, name='conv-max-3')\n",
    "        convmax4 = conv_maxpool(inputs=convmax3, num_filters=128, name='conv-max-4')\n",
    "\n",
    "        with tf.name_scope('flat'):\n",
    "            pool_flat = tf.reshape(convmax4, shape=[-1, 128 * 8 * 8])\n",
    "\n",
    "        with tf.name_scope('fc-1'):\n",
    "            dense = tf.layers.dense(inputs=pool_flat, units=1024, activation=tf.nn.relu)\n",
    "        with tf.name_scope('drop-out-1'):\n",
    "            dropout = tf.layers.dropout(inputs=dense, rate=0.5)\n",
    "\n",
    "        # Logits Layer\n",
    "        with tf.name_scope('logits-1'):\n",
    "            logits = tf.layers.dense(inputs=dropout, units=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('ops-1'):\n",
    "        xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "        loss = tf.reduce_mean(xentropy)\n",
    "        optimizer = tf.train.AdamOptimizer()\n",
    "        training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('summary'):\n",
    "        correct = tf.nn.in_top_k(logits, y, 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "step = 0\n",
    "prev_best = 0\n",
    "num_epochs = 20\n",
    "batch_size = 20\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(len(X_train) // batch_size):\n",
    "            X_train_batch = fetch_batch(X_train, i, batch_size)\n",
    "            Y_train_batch = fetch_batch(Y_train, i, batch_size)\n",
    "            \n",
    "            sess.run(training_op, feed_dict={X: X_train_batch, y: Y_train_batch})\n",
    "\n",
    "            step += 1\n",
    "            val_accs = []\n",
    "            if step % 10 == 0:    \n",
    "                val_accs[:] = []\n",
    "\n",
    "                for j in range(len(X_val) // batch_size):\n",
    "                    X_val_batch = fetch_batch(X_val, j, batch_size)\n",
    "                    y_val_batch = fetch_batch(y_val, j, batch_size)\n",
    "\n",
    "                    val_acc = sess.run(accuracy, feed_dict={X:X_val_batch, y: y_val_batch})\n",
    "                    val_accs.append(val_acc)\n",
    "\n",
    "                temp_acc = sum(val_accs)/len(val_accs)\n",
    "                train_acc = sess.run(accuracy, feed_dict={X:X_train_batch, y: Y_train_batch})\n",
    "\n",
    "                print('{}-{} Train acc: {} Val acc: {}'.format(epoch, step, train_acc, temp_acc))\n",
    "                if temp_acc > prev_best:\n",
    "                    print('... save new best model')\n",
    "                    prev_best = temp_acc\n",
    "                    save_path = saver.save(sess, \"models/model-{}-{:2.2f}.ckpt\".format(epoch, temp_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure against unseen test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    saver.restore(sess, './models/model-2-0.64.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
